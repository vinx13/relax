{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed492fce",
   "metadata": {},
   "source": [
    "# Demo of optimization without weights in Relax\n",
    "\n",
    "There are use cases that the model weights are not availble at compile-time. This notebook demonstrates how to perform the same optimizations that may change the model weights in Relax. The idea is to identify the transformations applied to the weights, lift and compile them into a separate `transform_params` function that will be shipped as part of the package for users to invoke in runtime with the real weights. \n",
    "\n",
    "There are several advantages of this approach:\n",
    "* `transform_params` is called by the users after they load the real weights. Re-packaging or re-compilation is not needed.\n",
    "* `transform_params` only need to be invoked once. There are no overhead during model benchmarking and inference.\n",
    "* The same set of optimizations can be performed. The model will have the same performance as when the weights are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8208f",
   "metadata": {},
   "source": [
    "## Example \n",
    "Let's start with a simple model that contains one layer of conv2d.\n",
    "In this example, the weight of `conv2d`, `w1`, is a input tensor of the entry function `main` that is not available in the compile-time. We used the annotatoin `param_begin`, `param_end` to mark the range indices of the function inputs that are model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6b8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.script import relax as R, tir as T\n",
    "import numpy as np\n",
    "\n",
    "target = tvm.target.Target(\"llvm\")\n",
    "dev = tvm.cpu(0)\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class Module0:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 3, 224, 224), \"float32\"), w1: R.Tensor((3, 16, 3, 3), \"float32\")) -> R.Tensor((1, 16, 224, 224), \"float32\"):\n",
    "        R.func_attr({'param_begin': 1, 'param_end': 2})  # [begin, end] are range of indices of the function params\n",
    "        with R.dataflow():\n",
    "            conv1 =  R.nn.conv2d(x, w1, padding=(1, 1), data_layout=\"NCHW\", kernel_layout=\"IOHW\")\n",
    "            R.output(conv1)\n",
    "        return conv1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f02fe5",
   "metadata": {},
   "source": [
    "We will apply graph transformations. Take weight layout rewrite as an example, it will insert layout_transform functions to the IRModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d49044",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class Module1:\n",
    "    @T.prim_func\n",
    "    def transform_layout_IOHW_to_OIHW(w1: T.Buffer((3, 16, 3, 3), \"float32\"), out: T.Buffer((16, 3, 3, 3), \"float32\")) -> None:\n",
    "        for ax0, ax1, ax2, ax3 in T.grid(16, 3, 3, 3):\n",
    "            with T.block(\"layout_transform\"):\n",
    "                o, i, h, w = T.axis.remap(\"SSSS\", [ax0, ax1, ax2, ax3])\n",
    "                out[o, i, h, w] = w1[i, o, h, w]\n",
    "\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 3, 224, 224), \"float32\"), w1: R.Tensor((3, 16, 3, 3), \"float32\")) -> R.Tensor((1, 16, 224, 224), \"float32\"):\n",
    "        R.func_attr({'param_begin': 1, 'param_end': 2})  # annotate the tensors that are parameters, [begin, end] are range of indices of the function params\n",
    "        with R.dataflow():\n",
    "            w1_transformed = R.call_tir(transform_layout_IOHW_to_OIHW, w1, R.Tensor((16, 3, 3, 3), \"float32\"))  # this is weight transformation generated by passes like RewriteWeightLayout\n",
    "            conv1 =  R.nn.conv2d(x, w1_transformed, padding=(1, 1), data_layout=\"NCHW\", kernel_layout=\"OIHW\")\n",
    "            R.output(conv1)\n",
    "        return conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bdd800",
   "metadata": {},
   "source": [
    "After graph optimizations have been applied, we will invoke the `LiftTransformParams` pass to lift the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161c3048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transform_layout_IOHW_to_OIHW</span>(\n",
       "        w1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], out: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;layout_transform&quot;</span>):\n",
       "                o, i, h, w <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [ax0, ax1, ax2, ax3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(w1[i, o, h, w])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(out[o, i, h, w])\n",
       "                out[o, i, h, w] <span style=\"color: #AA22FF; font-weight: bold\">=</span> w1[i, o, h, w]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        params: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)),\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> params[<span style=\"color: #008000\">0</span>]\n",
       "            conv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(\n",
       "                x,\n",
       "                lv,\n",
       "                strides<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>],\n",
       "                padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>],\n",
       "                dilation<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>],\n",
       "                groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>,\n",
       "                data_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>,\n",
       "                kernel_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>,\n",
       "                out_layout<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>,\n",
       "                out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;&quot;</span>,\n",
       "            )\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(conv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> conv1\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transform_params</span>(\n",
       "        params1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> params1[<span style=\"color: #008000\">0</span>]\n",
       "            lv11 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                transform_layout_IOHW_to_OIHW,\n",
       "                (lv1,),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> (lv11,)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=1):\n",
    "    seq = tvm.transform.Sequential([relax.transform.LiftTransformParams()])\n",
    "    mod = seq(Module1)\n",
    "assert relax.analysis.well_formed(mod)\n",
    "\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b3694",
   "metadata": {},
   "source": [
    "The new module contains `transform_params` function which takes a tuple of weights as the input and outputs a tuple of the optimized weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda0700",
   "metadata": {},
   "source": [
    "We will then run the usual compilation flow to build the Relax VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd63312",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod = relax.transform.LegalizeOps()(mod)\n",
    "exec = relax.vm.build(mod, target, params=None)  # optimize and compile the model without params\n",
    "vm = relax.vm.VirtualMachine(exec, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7624b7",
   "metadata": {},
   "source": [
    "With the built package, users can feed in the real weights to get the weights for the optimized model. (This step happens solely on the user side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bf082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these weights are only available at runtime\n",
    "w1 = tvm.nd.array(np.random.uniform(size=(3, 16, 3, 3)).astype(dtype=\"float32\"), dev)\n",
    "params = tvm.runtime.container.tuple_object((w1,))\n",
    "transformed_params = vm[\"transform_params\"](params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf49b11",
   "metadata": {},
   "source": [
    "With the transformed parameters, users can run the model inference in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98fb1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tvm.nd.array(np.random.uniform(size=(1, 3, 224, 224)).astype(dtype=\"float32\"), dev)\n",
    "out = vm[\"main\"](x, transformed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3d9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "import tvm.topi.testing\n",
    "ref_out = tvm.topi.testing.conv2d_nchw_python(x.numpy(), w1.numpy().transpose(1, 0, 2, 3), stride=1, padding=1)\n",
    "tvm.testing.assert_allclose(ref_out, out.numpy(), atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3e30e",
   "metadata": {},
   "source": [
    "## Integration with the end-to-end workflow\n",
    "This approach can be integrated with the end-to-end workflow with the following changes needed:\n",
    "- The frontend need to annotate the model inputs that are the weights. For example, when the weights are not provided, the frontend may produce a function with input list (x, w1, w2,), it need to detect `w1, w2` and annotate them as weights.\n",
    "- The `LiftTransformParams` pass will be added to the compilation pipeline after graph optimization passes have been performed.\n",
    "- The users will need to invoke `transform_params` API to get the weights for the optimized model before inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
